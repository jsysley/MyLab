############################Python自然语言处理
基于Python编程语言及其自然语言工具包Natural Language Toolkit，NLTK
############################第一章 语言处理与python
1.1语言计算：文本和单词
计数词汇：
	标识符：表示一个我们想要放在一组对待的字符序列
	词类型：指一个词在一个文本中独一无二的出现形式或拼写
	类型：包括独一无二的标点和词类型
	文本词汇丰富度：len(text)/len(set(text))
1.2近观python：将文本当做词链表
	链表（list）

1.5自动理解自然语言
	词意消歧：我们要算出特定上下文的词被赋予的是哪个意思
	指代消解(anaphora resolution)：检测主语和动词的宾语,确定代词或名词短语指的是什么
	语义角色标注(semantic role labeling)：确定名词短语如何与动词关联（如施事，受事，工具等）
	自动生成语言
	机器翻译
		给出一个德文和英文双语的文档或者一个双语词典，我们就可以自动配对组成句子，这个过程叫文本对齐
	人机对话系统
		在人工智能历史上，主要的智能测试是一个语言学测试，图灵测试；一个响应用户文本输入的对话系统能否表现的自然到我们无法区分它是人工生成的响应。
	文本的含义
		文本语义识别（Recognizing Textual Entailment,RTE）
	NPL局限性：
		尽管有进展，但在现实世界中应用中已经部署的语言理解系统仍不能进行常识推理或以一种一般的可靠方式描绘这个世界的知识

############################中文分词技术
分词（中文分词技术）
	基于字典、词库匹配的分词方法
		逐词遍历法
			逐词遍历法将词典中的所有词按由长到短的顺序在文章中逐字搜索,直至文章结束。
			这种方法效率比较低，大一点的系统一般都不使用。
		基于字典、词库匹配的分词方法（机械分词法）
			这种方法按照一定策略将待分析的汉字串与一个“充分大的”机器词典中的词条进行匹配，若在词典中找到某个字符串，则匹配成功。
			据扫描方向的不同分为正向匹配和逆向匹配。根据不同长度优先匹配的情况，分为最大（最长）匹配和最小（最短）匹配。
			根据与词性标注过程是否相结合，又可以分为单纯分词方法和分词与标注相结合的一体化方法
				最大正向匹配法（Maximum Matching Method,MM）
					假定分词词典中的最长词有i个汉字字符，则用被处理文档的当前字串中的前i个字作为匹配字段，查找字典。若字典中存在这样的一个i字词，则匹配成功，匹配字段被作为一个词切分出来。如果词典中找不到这样的一个i字词，则匹配失败，将匹配字段中的最后一个字去掉，对剩下的字串重新进行匹配处理……  如此进行下去，直到匹配成功，即切分出一个词或剩余字串的长度为零为止。这样就完成了一轮匹配，然后取下一个i字字串进行匹配处理，直到文档被扫描完为止.
				逆向最大匹配法（Reverse Maximum Matching Method,RMM）
					ＲＭＭ法的基本原理与ＭＭ法相同 ,不同的是分词切分的方向与MM法相反，而且使用的分词辞典也不同。逆向最大匹配法从被处理文档的末端开始匹配扫描，每次取最末端的2i个字符（i字字串）作为匹配字段，若匹配失败，则去掉匹配字段最前面的一个字，继续匹配。相应地，它使用的分词词典是逆序词典，其中的每个词条都将按逆序方式存放。在实际处理时，先将文档进行倒排处理，生成逆序文档。然后，根据逆序词典，对逆序文档用正向最大匹配法处理即可。
				评价：
					由于汉语中偏正结构较多，若从后向前匹配，可以适当提高精确度。所以，逆向最大匹配法比正向最大匹配法的误差要小。
					最大匹配算法是一种基于分词词典的机械分词法，不能根据文档上下文的语义特征来切分词语，对词典的依赖性较大，所以在实际使用时，难免会造成一些分词错误，为了提高系统分词的准确度，可以采用正向最大匹配法和逆向最大匹配法相结合的分词方案（即双向匹配法.
				最少切分法：使每一句中切出的词数最小。
				双向匹配法：将正向最大匹配法与逆向最大匹配法组合。先根据标点对文档进行粗切分，把文档分解成若干个句子，然后再对这些句子用正向最大匹配法和逆向最大匹配法进行扫描切分。如果两种分词方法得到的匹配结果相同，则认为分词正确，否则，按最小集处理。

	基于词频度统计的分词方法
		全切分和基于词的频度统计的分词方法
			全切分
				全切分要求获得输入序列的所有可接受的切分形式，而部分切分只取得一种或几种可接受的切分形式，由于部分切分忽略了可能的其他切分形式，所以建立在部分切分基础上的分词方法不管采取何种歧义纠正策略，都可能会遗漏正确的切分，造成分词错误或失败。而建立在全切分基础上的分词方法，由于全切分取得了所有可能的切分形式，因而从根本上避免了可能切分形式的遗漏，克服了部分切分方法的缺陷
				全切分算法能取得所有可能的切分形式，它的句子覆盖率和分词覆盖率均为100%，但全切分分词并没有在文本处理中广泛地采用，原因有以下几点：
					1)全切分算法只是能获得正确分词的前提，因为全切分不具有歧义检测功能，最终分词结果的正确性和完全性依赖于独立的歧义处理方法，如果评测有误，也会造成错误的结果。
					2)全切分的切分结果个数随句子长度的增长呈指数增长，一方面将导致庞大的无用数据充斥于存储数据库；另一方面当句长达到一定长度后，由于切分形式过多,造成分词效率严重下降。
		这是一种全切分方法。它不依靠词典,而是将文章中任意两个字同时出现的频率进行统计,次数越高的就可能是一个词。它首先切分出与词表匹配的所有可能的词,运用统计语言模型和决策算法决定最优的切分结果。它的优点在于可以发现所有的切分歧义并且容易将新词提取出来。
	基于知识理解的分词方法
		该方法主要基于句法、语法分析，并结合语义分析，通过对上下文内容所提供信息的分析对词进行定界，它通常包括三个部分：分词子系统、句法语义子系统、总控部分。在总控部分的协调下，分词子系统可以获得有关词、句子等的句法和语义信息来对分词歧义进行判断。这类方法试图让机器具有人类的理解能力，需要使用大量的语言知识和信息。由于汉语语言知识的笼统、复杂性，难以将各种语言信息组织成机器可直接读取的形式。因此目前基于知识的分词系统还处在试验阶段。
词性标注（Part of Speech tagging,POS tagging）
	是指为分词结果中的每个单词标注一个正确的词性的程序，也即确定每个词是名词、动词、形容词或其他词性的过程.
名实体识别（Named Enitity Recogntion,NEP）
	是指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等。 
		基于规则和词典方法（MUC-6会议中几乎所有参赛人员都采用基于规则方法）
			该方法需要专家制定规则，准确率较高，但依赖于特征领域，可以执行差。
		基于统计方法
			主要采用HMM、MEMM、CRF，难点在于特征选择上，该方法能获得好的鲁棒性和灵活性，不需要太多的人工干预和领域限制，但需要大量的标注集。
		混合方法：采用规则与统计结合，多种统计方法相结合等，是目前主流的方法。
		特征：上下文信息+构词法
指代消解
	指一种常见的语言现象，一般情况下，指代分2种，回指和共指
		回指
			指当前的照应语与上文出现的词、短语或句子(句群）存在密切的语义关联性，指代依存于上下文语义中，在不同的语言环境中可能指代不同的实体，具有非对称性和非传递性。
		共指
			主要是指2个名词(包括代名词、名词短语)指向真实世界中的同一参照体，这种指代脱离上下文仍然成立。 
		目前指代消解研究主要侧重于等价关系，只考虑2个词或短语是否指示现实世界中同一实体的问题，即共指消解。
		中文指代三种形式
			人称代词、指示代词、有定描述





